"""
LiteLLM Provider Configuration Manager
ç”¨äºç®¡ç† Onyx ä¸­çš„ LLM Provider é…ç½®

æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼š/Users/zhuxiaofeng/Github/onyx/backend/test/llm_provider_manager.py
"""

import requests
import json
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum


class ProviderType(str, Enum):
    """æ”¯æŒçš„ LLM æä¾›å•†ç±»å‹"""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    AZURE = "azure"
    BEDROCK = "bedrock"
    VERTEX_AI = "vertex_ai"


@dataclass
class ModelConfiguration:
    """æ¨¡å‹é…ç½®æ•°æ®ç±»"""
    name: str
    is_visible: bool = True
    max_input_tokens: Optional[int] = None
    api_key: Optional[str] = None
    api_base: Optional[str] = None


@dataclass
class LLMProviderConfig:
    """LLM Provideré…ç½®æ•°æ®ç±»"""
    name: str
    provider: str
    api_key: Optional[str] = None
    api_base: Optional[str] = None
    api_version: Optional[str] = None
    custom_config: Optional[Dict[str, str]] = None
    default_model_name: str = "gpt-3.5-turbo"
    fast_default_model_name: Optional[str] = None
    deployment_name: Optional[str] = None
    is_public: bool = True
    groups: List[int] = None
    default_vision_model: Optional[str] = None
    model_configurations: List[ModelConfiguration] = None
    
    def __post_init__(self):
        if self.groups is None:
            self.groups = []
        if self.model_configurations is None:
            self.model_configurations = []


class LLMProviderManager:
    """
    LLM Provider é…ç½®ç®¡ç†å™¨
    ç”¨äºç®¡ç† litellm æ¨¡å‹çš„é…ç½®å’Œæµ‹è¯•
    """
    
    def __init__(self, base_url: str = "http://localhost:8080", admin_token: Optional[str] = None):
        """
        åˆå§‹åŒ–LLM Providerç®¡ç†å™¨
        
        Args:
            base_url: åç«¯æœåŠ¡çš„åŸºç¡€URL
            admin_token: ç®¡ç†å‘˜è®¤è¯tokenï¼ˆå¦‚æœéœ€è¦ï¼‰
        """
        self.base_url = base_url.rstrip("/")
        self.admin_token = admin_token
        self.headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        # å¦‚æœæä¾›äº†è®¤è¯tokenï¼Œæ·»åŠ åˆ°headersä¸­
        if self.admin_token:
            self.headers["Authorization"] = f"Bearer {self.admin_token}"
    
    def create_provider(self, config: LLMProviderConfig) -> Dict[str, Any]:
        """
        åˆ›å»ºæ–°çš„LLM Provider
        
        Args:
            config: LLM Provideré…ç½®
            
        Returns:
            åˆ›å»ºçš„Providerä¿¡æ¯
        """
        url = f"{self.base_url}/admin/llm/provider"
        
        # è½¬æ¢é…ç½®ä¸ºè¯·æ±‚æ•°æ®
        payload = self._config_to_payload(config)
        
        # å‘é€åˆ›å»ºè¯·æ±‚
        response = requests.put(
            url,
            params={"is_creation": True},
            json=payload,
            headers=self.headers
        )
        
        if response.status_code != 200:
            raise Exception(f"åˆ›å»ºProviderå¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def update_provider(self, config: LLMProviderConfig) -> Dict[str, Any]:
        """
        æ›´æ–°ç°æœ‰çš„LLM Provider
        
        Args:
            config: LLM Provideré…ç½®
            
        Returns:
            æ›´æ–°åçš„Providerä¿¡æ¯
        """
        url = f"{self.base_url}/admin/llm/provider"
        
        # è½¬æ¢é…ç½®ä¸ºè¯·æ±‚æ•°æ®
        payload = self._config_to_payload(config)
        
        # å‘é€æ›´æ–°è¯·æ±‚
        response = requests.put(
            url,
            params={"is_creation": False},
            json=payload,
            headers=self.headers
        )
        
        if response.status_code != 200:
            raise Exception(f"æ›´æ–°Providerå¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def test_provider(self, config: LLMProviderConfig) -> bool:
        """
        æµ‹è¯•LLM Provideré…ç½®
        
        Args:
            config: LLM Provideré…ç½®
            
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/llm/test"
        
        # æ„é€ æµ‹è¯•è¯·æ±‚æ•°æ®
        payload = {
            "name": config.name,
            "provider": config.provider,
            "api_key": config.api_key,
            "api_base": config.api_base,
            "api_version": config.api_version,
            "custom_config": config.custom_config,
            "default_model_name": config.default_model_name,
            "fast_default_model_name": config.fast_default_model_name,
            "deployment_name": config.deployment_name,
            "model_configurations": [asdict(mc) for mc in config.model_configurations],
            "api_key_changed": True
        }
        
        response = requests.post(
            url,
            json=payload,
            headers=self.headers
        )
        
        if response.status_code == 200:
            return True
        else:
            print(f"æµ‹è¯•å¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def list_providers(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰LLM Provideråˆ—è¡¨
        
        Returns:
            Provideråˆ—è¡¨
        """
        url = f"{self.base_url}/admin/llm/provider"
        
        response = requests.get(url, headers=self.headers)
        
        if response.status_code != 200:
            raise Exception(f"è·å–Provideråˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def delete_provider(self, provider_id: int) -> bool:
        """
        åˆ é™¤æŒ‡å®šçš„LLM Provider
        
        Args:
            provider_id: Provider ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/llm/provider/{provider_id}"
        
        response = requests.delete(url, headers=self.headers)
        
        if response.status_code == 200:
            return True
        else:
            print(f"åˆ é™¤Providerå¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def set_default_provider(self, provider_id: int, default_model: str = None, fast_model: str = None) -> bool:
        """
        è®¾ç½®æŒ‡å®šProviderä¸ºé»˜è®¤Providerï¼Œå¹¶å¯é€‰è®¾ç½®é»˜è®¤æ¨¡å‹å’Œå¿«é€Ÿæ¨¡å‹
        
        Args:
            provider_id: Provider ID
            default_model: é»˜è®¤æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            fast_model: å¿«é€Ÿæ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        # å…ˆè®¾ç½®ä¸ºé»˜è®¤Provider
        url = f"{self.base_url}/admin/llm/provider/{provider_id}/default"
        response = requests.post(url, headers=self.headers)
        
        if response.status_code != 200:
            print(f"è®¾ç½®é»˜è®¤Providerå¤±è´¥: {response.status_code} - {response.text}")
            return False
        
        # å¦‚æœéœ€è¦æ›´æ–°æ¨¡å‹é…ç½®ï¼Œè°ƒç”¨æ›´æ–°API
        if default_model or fast_model:
            provider = self.get_provider_by_id(provider_id)
            if provider:
                config = self._provider_to_config(provider)
                if default_model: config.default_model_name = default_model
                if fast_model: config.fast_default_model_name = fast_model
                self.update_provider(config)
        
        return True
    
    def set_default_vision_provider(self, provider_id: int, vision_model: Optional[str] = None) -> bool:
        """
        è®¾ç½®æŒ‡å®šProviderä¸ºé»˜è®¤è§†è§‰Provider
        
        Args:
            provider_id: Provider ID
            vision_model: è§†è§‰æ¨¡å‹åç§°
            
        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/llm/provider/{provider_id}/default-vision"
        params = {}
        if vision_model:
            params["vision_model"] = vision_model
        
        response = requests.post(url, params=params, headers=self.headers)
        
        if response.status_code == 200:
            return True
        else:
            print(f"è®¾ç½®é»˜è®¤è§†è§‰Providerå¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def get_provider_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®åç§°è·å–Providerä¿¡æ¯
        
        Args:
            name: Provideråç§°
            
        Returns:
            Providerä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        providers = self.list_providers()
        for provider in providers:
            if provider.get("name") == name:
                return provider
        return None
    
    def get_provider_by_id(self, provider_id: int) -> Optional[Dict[str, Any]]:
        """æ ¹æ®IDè·å–Providerä¿¡æ¯"""
        providers = self.list_providers()
        for provider in providers:
            if provider.get("id") == provider_id:
                return provider
        return None
    
    def _provider_to_config(self, provider: Dict[str, Any], original_api_key: str = None) -> LLMProviderConfig:
        """å°†Providerå­—å…¸è½¬æ¢ä¸ºé…ç½®å¯¹è±¡"""
        return LLMProviderConfig(
            name=provider.get("name"),
            provider=provider.get("provider"),
            api_key=original_api_key or "sk-Zd7gzQGylVwOyUUMvOBhow",  # ğŸ”‘ ä½¿ç”¨åŸå§‹APIå¯†é’¥
            api_base=provider.get("api_base"),
            api_version=provider.get("api_version"),
            custom_config=provider.get("custom_config"),
            default_model_name=provider.get("default_model_name"),
            fast_default_model_name=provider.get("fast_default_model_name"),
            deployment_name=provider.get("deployment_name"),
            is_public=provider.get("is_public", True),
            groups=provider.get("groups", [])
        )
    
    def create_or_update_provider(self, config: LLMProviderConfig) -> Dict[str, Any]:
        """
        åˆ›å»ºæˆ–æ›´æ–°Providerï¼ˆå¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºï¼‰
        
        Args:
            config: LLM Provideré…ç½®
            
        Returns:
            Providerä¿¡æ¯
        """
        existing = self.get_provider_by_name(config.name)
        
        if existing:
            print(f"Provider '{config.name}' å·²å­˜åœ¨ï¼Œæ‰§è¡Œæ›´æ–°æ“ä½œ")
            return self.update_provider(config)
        else:
            print(f"Provider '{config.name}' ä¸å­˜åœ¨ï¼Œæ‰§è¡Œåˆ›å»ºæ“ä½œ")
            return self.create_provider(config)
    
    def _config_to_payload(self, config: LLMProviderConfig) -> Dict[str, Any]:
        """
        å°†é…ç½®å¯¹è±¡è½¬æ¢ä¸ºAPIè¯·æ±‚æ•°æ®
        
        Args:
            config: LLM Provideré…ç½®
            
        Returns:
            APIè¯·æ±‚æ•°æ®
        """
        payload = {
            "name": config.name,
            "provider": config.provider,
            "api_key": config.api_key,
            "api_base": config.api_base,
            "api_version": config.api_version,
            "custom_config": config.custom_config,
            "default_model_name": config.default_model_name,
            "fast_default_model_name": config.fast_default_model_name,
            "deployment_name": config.deployment_name,
            "is_public": config.is_public,
            "groups": config.groups,
            "default_vision_model": config.default_vision_model,
            "model_configurations": [asdict(mc) for mc in config.model_configurations],
            "api_key_changed": True  # ğŸ”‘ å…³é”®ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨åŸå§‹APIå¯†é’¥è€Œä¸æ˜¯åŠ å¯†åçš„å¯†é’¥
        }
        
        # ç§»é™¤Noneå€¼
        return {k: v for k, v in payload.items() if v is not None}

    def configure_llm_models(self, provider_name: str, default_model: str, fast_model: str = None) -> bool:
        """
        ä¸“é—¨é…ç½®æŒ‡å®š Provider çš„ LLM æ¨¡å‹é…ç½®
        
        Args:
            provider_name: Provider åç§°
            default_model: é»˜è®¤æ¨¡å‹åç§°
            fast_model: å¿«é€Ÿæ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é…ç½®æ˜¯å¦æˆåŠŸ
        """
        try:
            # è·å–ç°æœ‰ Provider
            provider = self.get_provider_by_name(provider_name)
            if not provider:
                print(f"âœ— æœªæ‰¾åˆ°åä¸º '{provider_name}' çš„ Provider")
                return False
            
            print(f"ğŸ”§ é…ç½® Provider '{provider_name}' çš„ LLM æ¨¡å‹...")
            print(f"  é»˜è®¤æ¨¡å‹: {default_model}")
            if fast_model:
                print(f"  å¿«é€Ÿæ¨¡å‹: {fast_model}")
            
            # è½¬æ¢ä¸ºé…ç½®å¯¹è±¡ï¼Œç¡®ä¿ä½¿ç”¨åŸå§‹APIå¯†é’¥
            config = self._provider_to_config(provider, "sk-Zd7gzQGylVwOyUUMvOBhow")
            config.default_model_name = default_model
            if fast_model:
                config.fast_default_model_name = fast_model
            
            # ç¡®ä¿æ¨¡å‹é…ç½®åŒ…å«è¿™äº›æ¨¡å‹
            model_names = {default_model}
            if fast_model:
                model_names.add(fast_model)
            
            # æ›´æ–°æˆ–æ·»åŠ æ¨¡å‹é…ç½®
            existing_models = {mc.name for mc in config.model_configurations}
            for model_name in model_names:
                if model_name not in existing_models:
                    config.model_configurations.append(
                        ModelConfiguration(name=model_name, is_visible=True, max_input_tokens=8192,api_key=config.api_key,api_base=config.api_base)
                    )
            
            # æ›´æ–° Provider
            result = self.update_provider(config)
            print(f"âœ“ LLM æ¨¡å‹é…ç½®æˆåŠŸ")
            
            # è®¾ç½®ä¸ºé»˜è®¤ Providerï¼ˆç¡®ä¿ç³»ç»Ÿä½¿ç”¨è¿™ä¸ªé…ç½®ï¼‰
            provider_id = result.get('id')
            if self.set_default_provider(provider_id):
                print(f"âœ“ å·²è®¾ç½®ä¸ºé»˜è®¤ Provider")
            
            return True
            
        except Exception as e:
            print(f"âœ— LLM æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            return False

    def test_default_provider_config(self) -> bool:
        """
        æµ‹è¯•å½“å‰é»˜è®¤ Provider çš„é…ç½®æ˜¯å¦æ­£å¸¸
        
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/llm/test/default"
        
        try:
            response = requests.post(url, headers=self.headers)
            
            if response.status_code == 200:
                print("âœ“ é»˜è®¤ Provider é…ç½®æµ‹è¯•æˆåŠŸ")
                return True
            else:
                print(f"âœ— é»˜è®¤ Provider é…ç½®æµ‹è¯•å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            print(f"âœ— æµ‹è¯•é»˜è®¤ Provider é…ç½®æ—¶å‡ºé”™: {e}")
            return False

    def test_fast_model_config(self) -> bool:
        """
        æµ‹è¯•å¿«é€Ÿæ¨¡å‹çš„é…ç½®æ˜¯å¦æ­£å¸¸
        
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        try:
            # è·å–é»˜è®¤Providerä¿¡æ¯
            providers = self.list_providers()
            default_provider = None
            for p in providers:
                if p.get('is_default_provider'):
                    default_provider = p
                    break
            
            if not default_provider:
                print("âœ— æœªæ‰¾åˆ°é»˜è®¤ Provider")
                return False
            
            fast_model = default_provider.get('fast_default_model_name')
            if not fast_model:
                print("âœ— é»˜è®¤ Provider æ²¡æœ‰é…ç½®å¿«é€Ÿæ¨¡å‹")
                return False
            
            print(f"ğŸš€ æµ‹è¯•å¿«é€Ÿæ¨¡å‹: {fast_model}")
            
            # æ„é€ å¿«é€Ÿæ¨¡å‹æµ‹è¯•è¯·æ±‚
            test_config = self._provider_to_config(default_provider, "sk-Zd7gzQGylVwOyUUMvOBhow")
            test_config.default_model_name = fast_model  # ä¸´æ—¶å°†å¿«é€Ÿæ¨¡å‹è®¾ä¸ºé»˜è®¤æ¨¡å‹è¿›è¡Œæµ‹è¯•
            
            # æµ‹è¯•å¿«é€Ÿæ¨¡å‹
            if self.test_provider(test_config):
                print("âœ“ å¿«é€Ÿæ¨¡å‹é…ç½®æµ‹è¯•æˆåŠŸ")
                return True
            else:
                print("âœ— å¿«é€Ÿæ¨¡å‹é…ç½®æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¿«é€Ÿæ¨¡å‹é…ç½®æ—¶å‡ºé”™: {e}")
            return False


    def delete_llm_provider_by_name(self, provider_name: str) -> bool:
        """
        æ ¹æ®åç§°åˆ é™¤LLM Provider
        
        Args:
            provider_name: Provideråç§°
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            # ä½¿ç”¨ç°æœ‰çš„æ–¹æ³•è·å–provider
            target_provider = self.get_provider_by_name(provider_name)
            
            if target_provider:
                provider_id = target_provider.get("id")
                print(f"æ‰¾åˆ°è¦åˆ é™¤çš„ Provider: {provider_name} (ID: {provider_id})")
                return self.delete_provider(provider_id)  # ä½¿ç”¨ç°æœ‰çš„delete_provideræ–¹æ³•
            else:
                print(f"âœ— æœªæ‰¾åˆ°åä¸º '{provider_name}' çš„ LLM Provider")
                return False
                
        except Exception as e:
            print(f"âœ— åˆ é™¤æ“ä½œå¤±è´¥: {e}")
            return False


# é¢„å®šä¹‰çš„å¸¸ç”¨é…ç½®æ¨¡æ¿
class LLMProviderTemplates:
    """é¢„å®šä¹‰çš„LLM Provideré…ç½®æ¨¡æ¿"""
    
    @staticmethod
    def create_custom_openai_config(
        name: str,
        api_key: str,
        api_base: str,
        model_name: str,
        fast_model_name: Optional[str] = None,
        custom_headers: Optional[Dict[str, str]] = None,
        max_tokens: int = 4096
    ) -> LLMProviderConfig:
        """
        åˆ›å»ºè‡ªå®šä¹‰OpenAIå…¼å®¹çš„é…ç½®
        
        Args:
            name: Provideråç§°
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model_name: æ¨¡å‹åç§°
            fast_model_name: å¿«é€Ÿæ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            custom_headers: è‡ªå®šä¹‰è¯·æ±‚å¤´
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            LLM Provideré…ç½®
        """
        model_configs = [
            ModelConfiguration(name=model_name, is_visible=True, max_input_tokens=max_tokens)
        ]
        
        if fast_model_name:
            model_configs.append(
                ModelConfiguration(name=fast_model_name, is_visible=True, max_input_tokens=max_tokens)
            )
        
        return LLMProviderConfig(
            name=name,
            provider="openai",
            api_key=api_key,
            api_base=api_base,
            custom_config=custom_headers,
            default_model_name=model_name,
            fast_default_model_name=fast_model_name,
            model_configurations=model_configs
        )

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•è„šæœ¬
if __name__ == "__main__":
    """
    LLM Provider ç®¡ç†è„šæœ¬ä½¿ç”¨ç¤ºä¾‹
    """
    print("=== LLM Provider ç®¡ç†å·¥å…· ===\n")
    
    # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
    manager = LLMProviderManager()
    
    # ğŸ”§ è¯Šæ–­ fast_llm é…ç½®é—®é¢˜
    providers = manager.list_providers()
    for p in providers:
        if p.get('is_default_provider'): 
            print(f"é»˜è®¤Provider: {p.get('name')}, fast_model: {p.get('fast_default_model_name')}")
            print(f"é»˜è®¤Provider: {p.get('default_model_name')}")
    
    # åˆ é™¤åŒ…å« qwen3-0-6b çš„æ—§é…ç½®
    print("1. æ¸…ç†æ—§çš„ qwen3-0-6b é…ç½®...")
    providers = manager.list_providers()
    for p in providers:
        if p.get('fast_default_model_name') == 'qwen3-0-6b':
            manager.delete_provider(p.get('id'))
            print(f"âœ“ åˆ é™¤æ—§é…ç½®: {p.get('name')} (ID: {p.get('id')})")
            break
    else:
        print("âœ“ æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„é…ç½®")
    
    # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºåŸºç¡€ Provider
    print("\n2. åˆ›å»ºåŸºç¡€ OpenAI å…¼å®¹ Provider...")
    base_config = LLMProviderTemplates.create_custom_openai_config(
        name="openai",
        api_key="sk-Zd7gzQGylVwOyUUMvOBhow", 
        api_base="http://172.16.0.120:4000/v1",
        model_name="qwen/qwen3-30b",
    )
    
    try:
        result = manager.create_or_update_provider(base_config)
        print("âœ“ åŸºç¡€ Provider åˆ›å»ºæˆåŠŸ")
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸“é—¨é…ç½® LLM æ¨¡å‹
        print("\n3. ä¸“é—¨é…ç½® LLM æ¨¡å‹...")
        if manager.configure_llm_models(
            provider_name="openai",
            default_model="qwen/qwen3-30b", 
            fast_model="openai/qwen3-0-6b"
        ):
            print("âœ“ LLM æ¨¡å‹é…ç½®æˆåŠŸ")
            
            # ç¬¬å››æ­¥ï¼šæµ‹è¯•é»˜è®¤é…ç½®
            print("\n4. æµ‹è¯•é»˜è®¤ Provider é…ç½®...")
            default_test_success = manager.test_default_provider_config()
            
            # ç¬¬äº”æ­¥ï¼šæµ‹è¯•å¿«é€Ÿæ¨¡å‹é…ç½®
            print("\n5. æµ‹è¯•å¿«é€Ÿæ¨¡å‹é…ç½®...")
            fast_test_success = manager.test_fast_model_config()
            
            if default_test_success and fast_test_success:
                print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
            else:
                print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        else:
            print("âœ— LLM æ¨¡å‹é…ç½®å¤±è´¥")
            
    except Exception as e:
        print(f"âœ— Provider é…ç½®å¤±è´¥: {e}")
    
    # åˆ—å‡ºæ‰€æœ‰providers
    print("\n6. å½“å‰æ‰€æœ‰ LLM Providers:")
    try:
        providers = manager.list_providers()
        for provider in providers:
            is_default = provider.get('is_default_provider', False)
            default_mark = " [é»˜è®¤]" if is_default else ""
            print(f"  - ID: {provider.get('id')}, åç§°: {provider.get('name')}{default_mark}, "
                  f"Provider: {provider.get('provider')}, "
                  f"é»˜è®¤æ¨¡å‹: {provider.get('default_model_name')}")
    except Exception as e:
        print(f"âœ— è·å–Provideråˆ—è¡¨å¤±è´¥: {e}")
    
    print("\n=== é…ç½®å®Œæˆ ===")
    print("\nç°åœ¨åœ¨æµ‹è¯•ä¸­ä½¿ç”¨:")
    print("model_provider='openai'")
    print("model_version='lm_studio/qwen/qwen3-30b'")
    print("\nğŸ’¡ æç¤ºï¼šå¦‚æœä¸ä½¿ç”¨ llm_overrideï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨é»˜è®¤Provider")


def set_default_provider_by_name(provider_name: str = "openai"):
    """
    å¿«é€Ÿè®¾ç½®æŒ‡å®šåç§°çš„Providerä¸ºé»˜è®¤Provider
    
    Args:
        provider_name: Provideråç§°ï¼Œé»˜è®¤ä¸º"openai"
    """
    print(f"=== è®¾ç½® '{provider_name}' ä¸ºé»˜è®¤Provider ===")
    
    manager = LLMProviderManager()
    
    try:
        # è·å–Providerä¿¡æ¯
        provider = manager.get_provider_by_name(provider_name)
        if not provider:
            print(f"âœ— æœªæ‰¾åˆ°åä¸º '{provider_name}' çš„Provider")
            return False
        
        provider_id = provider.get('id')
        print(f"æ‰¾åˆ°Provider: {provider_name} (ID: {provider_id})")
        
        # è®¾ç½®ä¸ºé»˜è®¤
        if manager.set_default_provider(provider_id):
            print(f"âœ“ æˆåŠŸå°† '{provider_name}' è®¾ç½®ä¸ºé»˜è®¤Provider")
            return True
        else:
            print(f"âœ— è®¾ç½®å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— æ“ä½œå¤±è´¥: {e}")
        return False


# å¦‚æœåªæƒ³è®¾ç½®é»˜è®¤Providerï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š
# if __name__ == "__main__":
#     set_default_provider_by_name("openai") 