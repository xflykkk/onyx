#!/usr/bin/env python3
"""
Embedding Provider Configuration Manager
ç”¨äºç®¡ç† Onyx ä¸­çš„ Embedding Provider é…ç½®

æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼š/Users/zhuxiaofeng/Github/onyx/backend/test/embedding_provider_manager.py
"""

import requests
import json
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum


class EmbeddingProviderType(str, Enum):
    """æ”¯æŒçš„ Embedding æä¾›å•†ç±»å‹"""
    OPENAI = "openai"
    COHERE = "cohere"
    VOYAGE = "voyage"
    GOOGLE = "google"
    LITELLM = "litellm"
    AZURE = "azure"


@dataclass
class EmbeddingProviderConfig:
    """Embedding Provideré…ç½®æ•°æ®ç±»"""
    provider_type: str
    api_key: Optional[str] = None
    api_url: Optional[str] = None
    api_version: Optional[str] = None
    deployment_name: Optional[str] = None


@dataclass
class TestEmbeddingConfig:
    """æµ‹è¯• Embedding é…ç½®æ•°æ®ç±»"""
    provider_type: str
    model_name: str
    api_key: Optional[str] = None
    api_url: Optional[str] = None
    api_version: Optional[str] = None
    deployment_name: Optional[str] = None


class EmbeddingProviderManager:
    """
    Embedding Provider é…ç½®ç®¡ç†å™¨
    ç”¨äºç®¡ç† embedding æ¨¡å‹çš„é…ç½®å’Œæµ‹è¯•
    """
    
    def __init__(self, base_url: str = "http://localhost:8080", admin_token: Optional[str] = None):
        """
        åˆå§‹åŒ– Embedding Provider ç®¡ç†å™¨
        
        Args:
            base_url: åç«¯æœåŠ¡çš„åŸºç¡€URL
            admin_token: ç®¡ç†å‘˜è®¤è¯tokenï¼ˆå¦‚æœéœ€è¦ï¼‰
        """
        self.base_url = base_url.rstrip("/")
        self.admin_token = admin_token
        self.headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        # å¦‚æœæä¾›äº†è®¤è¯tokenï¼Œæ·»åŠ åˆ°headersä¸­
        if self.admin_token:
            self.headers["Authorization"] = f"Bearer {self.admin_token}"
    
    def list_embedding_providers(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ Embedding Provider åˆ—è¡¨
        
        Returns:
            Embedding Provideråˆ—è¡¨
        """
        url = f"{self.base_url}/admin/embedding/embedding-provider"
        
        response = requests.get(url, headers=self.headers)
        
        if response.status_code != 200:
            raise Exception(f"è·å– Embedding Provider åˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def create_or_update_embedding_provider(self, config: EmbeddingProviderConfig) -> Dict[str, Any]:
        """
        åˆ›å»ºæˆ–æ›´æ–° Embedding Provider
        
        Args:
            config: Embedding Provider é…ç½®
            
        Returns:
            Providerä¿¡æ¯
        """
        url = f"{self.base_url}/admin/embedding/embedding-provider"
        
        # è½¬æ¢é…ç½®ä¸ºè¯·æ±‚æ•°æ®
        payload = {
            "provider_type": config.provider_type,
            "api_key": config.api_key,
            "api_url": config.api_url,
            "api_version": config.api_version,
            "deployment_name": config.deployment_name,
        }
        
        # ç§»é™¤Noneå€¼
        payload = {k: v for k, v in payload.items() if v is not None}
        
        # å‘é€åˆ›å»º/æ›´æ–°è¯·æ±‚
        response = requests.put(
            url,
            json=payload,
            headers=self.headers
        )
        
        if response.status_code != 200:
            raise Exception(f"åˆ›å»º/æ›´æ–° Embedding Provider å¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def delete_embedding_provider(self, provider_type: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šçš„ Embedding Provider
        
        Args:
            provider_type: Provider ç±»å‹ï¼ˆå¦‚ "openai", "cohere" ç­‰ï¼‰
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/embedding/embedding-provider/{provider_type}"
        
        response = requests.delete(url, headers=self.headers)
        
        if response.status_code == 200:
            return True
        else:
            print(f"åˆ é™¤ Embedding Provider å¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def test_embedding_provider(self, config: TestEmbeddingConfig) -> bool:
        """
        æµ‹è¯• Embedding Provider é…ç½®
        
        Args:
            config: æµ‹è¯•é…ç½®
            
        Returns:
            æµ‹è¯•æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/admin/embedding/test-embedding"
        
        # æ„é€ æµ‹è¯•è¯·æ±‚æ•°æ®
        payload = {
            "provider_type": config.provider_type,
            "model_name": config.model_name,
            "api_key": config.api_key,
            "api_url": config.api_url,
            "api_version": config.api_version,
            "deployment_name": config.deployment_name,
        }
        
        # ç§»é™¤Noneå€¼
        payload = {k: v for k, v in payload.items() if v is not None}
        
        print(f"   è¯·æ±‚å‚æ•°: {payload}")
        
        response = requests.post(
            url,
            json=payload,
            headers=self.headers
        )
        
        if response.status_code == 200:
            print(f"   âœ“ æ¨¡å‹ '{config.model_name}' æµ‹è¯•æˆåŠŸ")
            return True
        else:
            print(f"   âœ— æ¨¡å‹ '{config.model_name}' æµ‹è¯•å¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def list_embedding_models(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ Embedding æ¨¡å‹åˆ—è¡¨
        
        Returns:
            Embedding æ¨¡å‹åˆ—è¡¨
        """
        url = f"{self.base_url}/admin/embedding"
        
        response = requests.get(url, headers=self.headers)
        
        if response.status_code != 200:
            raise Exception(f"è·å– Embedding æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text}")
        
        return response.json()
    
    def delete_embedding_model(self, search_settings_id: int) -> bool:
        """
        åˆ é™¤æŒ‡å®šçš„ Embedding æ¨¡å‹ï¼ˆé€šè¿‡ search_settings_idï¼‰
        
        Args:
            search_settings_id: æœç´¢è®¾ç½®ID
            
        Returns:
            åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/search-settings/delete-search-settings"
        
        payload = {
            "search_settings_id": search_settings_id
        }
        
        response = requests.delete(url, json=payload, headers=self.headers)
        
        if response.status_code == 200:
            return True
        else:
            print(f"åˆ é™¤ Embedding æ¨¡å‹å¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def get_current_active_embedding_model(self) -> Optional[Dict[str, Any]]:
        """
        è·å–å½“å‰æ´»è·ƒçš„ embedding æ¨¡å‹
        
        Returns:
            å½“å‰æ´»è·ƒçš„æ¨¡å‹ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        try:
            models = self.list_embedding_models()
            for model in models:
                if model.get('status') == 'PRESENT':
                    return model
            return None
        except Exception as e:
            print(f"âœ— è·å–æ´»è·ƒæ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def create_new_embedding_model(self, model_name: str, provider_type: str = "litellm") -> bool:
        """
        åˆ›å»ºæ–°çš„ embedding æ¨¡å‹é…ç½®
        
        Args:
            model_name: æ¨¡å‹åç§°
            provider_type: Provider ç±»å‹
            
        Returns:
            åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        url = f"{self.base_url}/search-settings/set-new-search-settings"
        
        payload = {
            "model_name": model_name,
            "model_dim": 1024,  # qwen3-embedding-0.6b çš„ç»´åº¦æ˜¯1024
            "normalize": True,
            "query_prefix": "",
            "passage_prefix": "",
            "provider_type": provider_type,
            "embedding_precision": "bfloat16",
            "multipass_indexing": True,
            "num_rerank": 5,
            "enable_contextual_rag": True,
            "index_name": None,  # è®©ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆç´¢å¼•åç§°
            "rerank_model_name": None,
            "rerank_api_url": None,
            "rerank_provider_type": None,
            "multilingual_expansion": []
        }
        
        print(f"   åˆ›å»ºæ¨¡å‹è¯·æ±‚å‚æ•°: {payload}")
        print(f"   è¯·æ±‚URL: {url}")
        
        response = requests.post(url, json=payload, headers=self.headers)
        
        print(f"   å“åº”çŠ¶æ€ç : {response.status_code}")
        print(f"   å“åº”å†…å®¹: {response.text}")
        
        if response.status_code == 200:
            print(f"   âœ“ æ¨¡å‹ '{model_name}' åˆ›å»ºæˆåŠŸ")
            return True
        else:
            print(f"   âœ— æ¨¡å‹ '{model_name}' åˆ›å»ºå¤±è´¥: {response.status_code} - {response.text}")
            return False
    
    def cleanup_old_qwen_models(self, skip_active: bool = True) -> bool:
        """
        æ¸…ç†æ‰€æœ‰ qwen ç›¸å…³çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ 4b å’Œ 0.6bï¼‰
        
        Args:
            skip_active: æ˜¯å¦è·³è¿‡æ´»è·ƒçŠ¶æ€çš„æ¨¡å‹
            
        Returns:
            æ¸…ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            models = self.list_embedding_models()
            old_models = []
            active_model = None
            
            # æ‰¾åˆ°æ‰€æœ‰åŒ…å« qwen çš„æ¨¡å‹
            for model in models:
                model_name = model.get('model_name', '')
                if 'qwen' in model_name.lower():
                    if model.get('status') == 'PRESENT':
                        active_model = model
                        if skip_active:
                            print(f"è·³è¿‡æ´»è·ƒæ¨¡å‹: {model_name} (ID: {model.get('id')})")
                            continue
                    old_models.append(model)
            
            if not old_models:
                print("âœ“ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„ qwen æ¨¡å‹")
                return True
            
            print(f"æ‰¾åˆ° {len(old_models)} ä¸ªéœ€è¦æ¸…ç†çš„ qwen æ¨¡å‹:")
            for model in old_models:
                status_text = model.get('status') or 'None'
                is_active = " [æ´»è·ƒ]" if model.get('status') == 'PRESENT' else ""
                print(f"  - æ¨¡å‹: {model.get('model_name')}, ID: {model.get('id')}, çŠ¶æ€: {status_text}{is_active}")
            
            if active_model and skip_active:
                print(f"\nâš ï¸ æ£€æµ‹åˆ°æ´»è·ƒæ¨¡å‹: {active_model.get('model_name')} (ID: {active_model.get('id')})")
                print("   éœ€è¦å…ˆè®¾ç½®æ–°çš„é»˜è®¤æ¨¡å‹ï¼Œç„¶åå†æ¸…ç†æ—§æ¨¡å‹")
                return False
            
            # åˆ é™¤è¿™äº›æ¨¡å‹
            success_count = 0
            for model in old_models:
                model_id = model.get('id')
                model_name = model.get('model_name')
                
                if self.delete_embedding_model(model_id):
                    print(f"âœ“ åˆ é™¤æ¨¡å‹æˆåŠŸ: {model_name} (ID: {model_id})")
                    success_count += 1
                else:
                    print(f"âœ— åˆ é™¤æ¨¡å‹å¤±è´¥: {model_name} (ID: {model_id})")
            
            print(f"æ¸…ç†å®Œæˆ: æˆåŠŸåˆ é™¤ {success_count}/{len(old_models)} ä¸ªæ¨¡å‹")
            return success_count == len(old_models)
            
        except Exception as e:
            print(f"âœ— æ¸…ç†æ—§æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def get_embedding_provider_by_type(self, provider_type: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®ç±»å‹è·å– Embedding Provider ä¿¡æ¯
        
        Args:
            provider_type: Providerç±»å‹
            
        Returns:
            Providerä¿¡æ¯ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        providers = self.list_embedding_providers()
        for provider in providers:
            if provider.get("provider_type") == provider_type:
                return provider
        return None
    
    def set_active_embedding_model(self, model_name: str) -> bool:
        """
        è®¾ç½®æŒ‡å®šçš„ embedding æ¨¡å‹ä¸ºå½“å‰æ´»è·ƒæ¨¡å‹
        é€šè¿‡åˆ›å»ºæ–°çš„æœç´¢è®¾ç½®æ¥åˆ‡æ¢æ¨¡å‹
        
        Args:
            model_name: è¦æ¿€æ´»çš„æ¨¡å‹åç§°
            
        Returns:
            è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. è·å–æ‰€æœ‰æ¨¡å‹åˆ—è¡¨
            models = self.list_embedding_models()
            target_model = None
            
            # 2. æ‰¾åˆ°ç›®æ ‡æ¨¡å‹
            for model in models:
                if model.get('model_name') == model_name:
                    target_model = model
                    break
            
            if not target_model:
                print(f"âœ— æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
                return False
            
            # 3. æ£€æŸ¥æ¨¡å‹çŠ¶æ€
            if target_model.get('status') == 'PRESENT':
                print(f"âœ“ æ¨¡å‹ '{model_name}' å·²ç»æ˜¯æ´»è·ƒçŠ¶æ€")
                return True
            
            # 4. ä½¿ç”¨ set-new-search-settings API æ¥åˆ›å»ºæ–°çš„æ´»è·ƒæ¨¡å‹
            url = f"{self.base_url}/search-settings/set-new-search-settings"
            
            # æ„é€ è¯·æ±‚æ•°æ®ï¼Œä½¿ç”¨ç›®æ ‡æ¨¡å‹çš„é…ç½®
            payload = {
                "model_name": target_model.get('model_name'),
                "model_dim": target_model.get('model_dim') or 1024,  # qwen3-embedding-0.6b é»˜è®¤ç»´åº¦æ˜¯1024
                "normalize": target_model.get('normalize', True),
                "query_prefix": target_model.get('query_prefix'),
                "passage_prefix": target_model.get('passage_prefix'),
                "provider_type": target_model.get('provider_type'),
                "embedding_precision": target_model.get('embedding_precision') or "bfloat16",
                "multipass_indexing": target_model.get('multipass_indexing', True),
                "num_rerank": target_model.get('num_rerank', 5),
                "enable_contextual_rag": target_model.get('enable_contextual_rag', True),
                "index_name": target_model.get('index_name'),  # ä½¿ç”¨ç°æœ‰çš„ç´¢å¼•åç§°
                "rerank_model_name": target_model.get('rerank_model_name'),
                "rerank_api_url": target_model.get('rerank_api_url'),
                "rerank_provider_type": target_model.get('rerank_provider_type'),
                "multilingual_expansion": target_model.get('multilingual_expansion', []),
                "background_reindex_enabled": False  # ä¸éœ€è¦é‡æ–°ç´¢å¼•ï¼Œç«‹å³åˆ‡æ¢
            }
            
            print(f"   æ¿€æ´»æ¨¡å‹è¯·æ±‚å‚æ•°: {payload}")
            print(f"   è¯·æ±‚URL: {url}")
            
            response = requests.post(url, json=payload, headers=self.headers)
            
            print(f"   å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"   å“åº”å†…å®¹: {response.text}")
            
            if response.status_code == 200:
                print(f"âœ“ æ¨¡å‹ '{model_name}' æ¿€æ´»æˆåŠŸ")
                return True
            else:
                print(f"âœ— æ¨¡å‹ '{model_name}' æ¿€æ´»å¤±è´¥: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            print(f"âœ— æ¿€æ´»æ¨¡å‹å¤±è´¥: {e}")
            return False


# é¢„å®šä¹‰çš„å¸¸ç”¨é…ç½®æ¨¡æ¿
class EmbeddingProviderTemplates:
    """é¢„å®šä¹‰çš„ Embedding Provider é…ç½®æ¨¡æ¿"""
    
    @staticmethod
    def create_openai_config(
        api_key: str,
        api_url: str = "http://172.16.0.120:4000/v1",
        api_version: Optional[str] = None
    ) -> EmbeddingProviderConfig:
        """
        åˆ›å»º OpenAI å…¼å®¹çš„ Embedding Provider é…ç½®
        
        Args:
            api_key: APIå¯†é’¥
            api_url: APIåŸºç¡€URL
            api_version: APIç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Embedding Provideré…ç½®
        """
        return EmbeddingProviderConfig(
            provider_type="openai",
            api_key=api_key,
            api_url=api_url,
            api_version=api_version
        )
    
    @staticmethod
    def create_test_config(
        provider_type: str,
        model_name: str,
        api_key: str,
        api_url: str = "http://172.16.0.120:4000/v1"
    ) -> TestEmbeddingConfig:
        """
        åˆ›å»ºæµ‹è¯•é…ç½®
        
        Args:
            provider_type: Providerç±»å‹
            model_name: æ¨¡å‹åç§°
            api_key: APIå¯†é’¥
            api_url: APIåŸºç¡€URL
            
        Returns:
            æµ‹è¯•é…ç½®
        """
        return TestEmbeddingConfig(
            provider_type=provider_type,
            model_name=model_name,
            api_key=api_key,
            api_url=api_url
        )


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•è„šæœ¬
if __name__ == "__main__":
    """
    Embedding Provider ç®¡ç†è„šæœ¬ä½¿ç”¨ç¤ºä¾‹
    """
    print("=== Embedding Provider ç®¡ç†å·¥å…· ===\n")
    
    # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
    manager = EmbeddingProviderManager()
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šåˆ—å‡ºå½“å‰æ‰€æœ‰ Embedding Providers
        print("1. å½“å‰æ‰€æœ‰ Embedding Providers:")
        providers = manager.list_embedding_providers()
        for provider in providers:
            print(f"  - ç±»å‹: {provider.get('provider_type')}, API URL: {provider.get('api_url')}")
        
        # ç¬¬äºŒæ­¥ï¼šåˆ—å‡ºå½“å‰æ‰€æœ‰ Embedding æ¨¡å‹åŠå…¶è¯¦ç»†ä¿¡æ¯
        print("\n2. å½“å‰æ‰€æœ‰ Embedding æ¨¡å‹:")
        models = manager.list_embedding_models()
        for model in models:
            status_map = {
                'PRESENT': 'æ´»è·ƒ',
                'FUTURE': 'å¾…æ¿€æ´»',
                'PAST': 'å·²åœç”¨',
                None: 'æœªå°±ç»ª'
            }
            status = status_map.get(model.get('status'), 'æœªçŸ¥')
            
            print(f"  - æ¨¡å‹: {model.get('model_name', 'N/A')}, "
                  f"Provider: {model.get('provider_type', 'N/A')}, "
                  f"çŠ¶æ€: {status}")
            
            # æ‰“å°è¯¦ç»†é…ç½®ä¿¡æ¯
            print(f"    è¯¦ç»†ä¿¡æ¯:")
            print(f"      ID: {model.get('id', 'N/A')}")
            print(f"      æ¨¡å‹ç»´åº¦: {model.get('model_dim', 'N/A')}")
            print(f"      è§„èŒƒåŒ–: {model.get('normalize', 'N/A')}")
            print(f"      æŸ¥è¯¢å‰ç¼€: '{model.get('query_prefix', '')}'")
            print(f"      æ®µè½å‰ç¼€: '{model.get('passage_prefix', '')}'")
            print(f"      ç´¢å¼•åç§°: {model.get('index_name', 'N/A')}")
            if model.get('api_key'):
                print(f"      APIå¯†é’¥: {model.get('api_key')[:10]}...")
            if model.get('api_url'):
                print(f"      API URL: {model.get('api_url')}")
            if model.get('api_version'):
                print(f"      APIç‰ˆæœ¬: {model.get('api_version')}")
            print()
        
        # ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„æ—§æ¨¡å‹ï¼ˆå…ˆä¸æ¸…ç†ï¼Œç•™åˆ°åé¢å¤„ç†ï¼‰
        print("\n3. æ£€æŸ¥æ—§çš„ qwen3-embedding-4b æ¨¡å‹...")
        active_model = manager.get_current_active_embedding_model()
        if active_model and 'qwen3-embedding-4b' in active_model.get('model_name', ''):
            print(f"âš ï¸ å‘ç°æ´»è·ƒçš„æ—§æ¨¡å‹: {active_model.get('model_name')} (ID: {active_model.get('id')})")
            print("   å°†åœ¨è®¾ç½®æ–°æ¨¡å‹åæ¸…ç†")
        
        # ç¬¬å››æ­¥ï¼šåˆ›å»ºæ–°çš„ OpenAI Embedding Provider é…ç½®
        print("\n4. åˆ›å»ºæ–°çš„ OpenAI Embedding Provider...")
        new_config = EmbeddingProviderTemplates.create_openai_config(
            api_key="sk-Zd7gzQGylVwOyUUMvOBhow",
            api_url="http://172.16.0.120:4000/v1/embeddings"
        )
        
        result = manager.create_or_update_embedding_provider(new_config)
        print("âœ“ OpenAI Embedding Provider åˆ›å»º/æ›´æ–°æˆåŠŸ")
        
        # ç¬¬äº”æ­¥ï¼šæµ‹è¯•æ–°çš„ embedding æ¨¡å‹é…ç½®
        print("\n5. æµ‹è¯•æ–°çš„ embedding æ¨¡å‹: qwen3-embedding-0.6b")
        test_config = EmbeddingProviderTemplates.create_test_config(
            provider_type="litellm",
            model_name="openai/qwen3-embedding-0.6b",
            api_key="sk-Zd7gzQGylVwOyUUMvOBhow",
            api_url="http://172.16.0.120:4000/v1/embeddings"
        )
        
        test_success = manager.test_embedding_provider(test_config)
        if test_success:
            print("âœ“ Embedding æ¨¡å‹æµ‹è¯•æˆåŠŸ")
        else:
            print("âœ— Embedding æ¨¡å‹æµ‹è¯•å¤±è´¥")
        
        # ç¬¬å…­æ­¥ï¼šæ˜¾ç¤ºæ›´æ–°åçš„é…ç½®
        print("\n6. æ›´æ–°åçš„ Embedding Providers:")
        providers = manager.list_embedding_providers()
        for provider in providers:
            print(f"  - ç±»å‹: {provider.get('provider_type')}, API URL: {provider.get('api_url')}")
        
        print("\n=== é…ç½®å®Œæˆ ===")
        print("\nğŸ’¡ ç°åœ¨ embedding æ¨¡å‹åº”è¯¥ä½¿ç”¨ openai/qwen3-embedding-0.6b è€Œä¸æ˜¯ qwen3-embedding-4b")
        
    except Exception as e:
        print(f"âœ— æ“ä½œå¤±è´¥: {e}")


def delete_embedding_provider_by_type(provider_type: str = "openai"):
    """
    å¿«é€Ÿåˆ é™¤æŒ‡å®šç±»å‹çš„ Embedding Provider
    
    Args:
        provider_type: Providerç±»å‹ï¼Œé»˜è®¤ä¸º"openai"
    """
    print(f"=== åˆ é™¤ '{provider_type}' Embedding Provider ===")
    
    manager = EmbeddingProviderManager()
    
    try:
        # æ£€æŸ¥Provideræ˜¯å¦å­˜åœ¨
        provider = manager.get_embedding_provider_by_type(provider_type)
        if not provider:
            print(f"âœ— æœªæ‰¾åˆ°ç±»å‹ä¸º '{provider_type}' çš„ Embedding Provider")
            return False
        
        print(f"æ‰¾åˆ° Embedding Provider: {provider_type}")
        
        # åˆ é™¤Provider
        if manager.delete_embedding_provider(provider_type):
            print(f"âœ“ æˆåŠŸåˆ é™¤ '{provider_type}' Embedding Provider")
            return True
        else:
            print(f"âœ— åˆ é™¤å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— æ“ä½œå¤±è´¥: {e}")
        return False


def list_all_embedding_models():
    """
    åˆ—å‡ºæ‰€æœ‰ embedding æ¨¡å‹å’Œå½“å‰æ´»è·ƒæ¨¡å‹
    """
    print("=== æ‰€æœ‰ Embedding æ¨¡å‹åˆ—è¡¨ ===")
    
    manager = EmbeddingProviderManager()
    
    try:
        # 1. è·å–å½“å‰æ´»è·ƒæ¨¡å‹
        print("1. å½“å‰æ´»è·ƒçš„ embedding æ¨¡å‹:")
        active_model = manager.get_current_active_embedding_model()
        if active_model:
            print(f"   ğŸŸ¢ æ´»è·ƒæ¨¡å‹: {active_model.get('model_name')} (ID: {active_model.get('id')})")
            print(f"      Provider: {active_model.get('provider_type')}")
            print(f"      ç»´åº¦: {active_model.get('model_dim')}")
            print(f"      ç´¢å¼•: {active_model.get('index_name')}")
        else:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒæ¨¡å‹")
        
        # 2. åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
        print("\n2. æ‰€æœ‰ Embedding æ¨¡å‹:")
        models = manager.list_embedding_models()
        
        if not models:
            print("   æ²¡æœ‰æ‰¾åˆ°ä»»ä½• embedding æ¨¡å‹")
            return
        
        status_map = {
            'PRESENT': 'ğŸŸ¢ æ´»è·ƒ',
            'FUTURE': 'ğŸŸ¡ å¾…æ¿€æ´»',
            'PAST': 'ğŸ”´ å·²åœç”¨',
            None: 'âšª æœªå°±ç»ª'
        }
        
        for i, model in enumerate(models, 1):
            status = status_map.get(model.get('status'), 'â“ æœªçŸ¥')
            print(f"   [{i}] {model.get('model_name', 'N/A')}")
            print(f"       çŠ¶æ€: {status}")
            print(f"       Provider: {model.get('provider_type', 'N/A')}")
            print(f"       ID: {model.get('id', 'N/A')}")
            print(f"       ç»´åº¦: {model.get('model_dim', 'N/A')}")
            print(f"       ç´¢å¼•: {model.get('index_name', 'N/A')}")
            if model.get('api_url'):
                print(f"       API URL: {model.get('api_url')}")
            print()
        
        # 3. ç»Ÿè®¡ä¿¡æ¯
        total_models = len(models)
        active_count = len([m for m in models if m.get('status') == 'PRESENT'])
        future_count = len([m for m in models if m.get('status') == 'FUTURE'])
        past_count = len([m for m in models if m.get('status') == 'PAST'])
        
        print(f"3. ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ¨¡å‹æ•°: {total_models}")
        print(f"   æ´»è·ƒæ¨¡å‹: {active_count}")
        print(f"   å¾…æ¿€æ´»æ¨¡å‹: {future_count}")
        print(f"   å·²åœç”¨æ¨¡å‹: {past_count}")
        
    except Exception as e:
        print(f"âœ— è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")


def delete_all_qwen_models():
    """
    åˆ é™¤æ‰€æœ‰ qwen ç›¸å…³çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬æ´»è·ƒæ¨¡å‹ï¼‰
    """
    print("=== åˆ é™¤æ‰€æœ‰ Qwen æ¨¡å‹ ===")
    
    manager = EmbeddingProviderManager()
    
    try:
        # å…ˆæ˜¾ç¤ºå½“å‰çŠ¶æ€
        print("1. å½“å‰ Qwen æ¨¡å‹çŠ¶æ€:")
        models = manager.list_embedding_models()
        qwen_models = [m for m in models if 'qwen' in m.get('model_name', '').lower()]
        
        if not qwen_models:
            print("   æ²¡æœ‰æ‰¾åˆ°ä»»ä½• qwen æ¨¡å‹")
            return True
        
        for model in qwen_models:
            status_text = model.get('status') or 'None'
            is_active = " [æ´»è·ƒ]" if model.get('status') == 'PRESENT' else ""
            print(f"   - æ¨¡å‹: {model.get('model_name')}, ID: {model.get('id')}, çŠ¶æ€: {status_text}{is_active}")
        
        # ç¡®è®¤åˆ é™¤
        print(f"\n2. å°†åˆ é™¤ {len(qwen_models)} ä¸ª qwen æ¨¡å‹")
        response = input("ç¡®è®¤åˆ é™¤æ‰€æœ‰ qwen æ¨¡å‹å—ï¼Ÿ(y/N): ")
        if response.lower() != 'y':
            print("å–æ¶ˆåˆ é™¤æ“ä½œ")
            return False
        
        # æ‰§è¡Œåˆ é™¤
        print("\n3. æ­£åœ¨åˆ é™¤ qwen æ¨¡å‹...")
        success = manager.cleanup_old_qwen_models(skip_active=False)
        
        if success:
            print("âœ“ æ‰€æœ‰ qwen æ¨¡å‹åˆ é™¤æˆåŠŸ")
        else:
            print("âš ï¸ éƒ¨åˆ† qwen æ¨¡å‹åˆ é™¤å¤±è´¥")
        
        return success
        
    except Exception as e:
        print(f"âœ— åˆ é™¤å¤±è´¥: {e}")
        return False


def setup_qwen_embedding():
    """
    è®¾ç½® qwen embedding æ¨¡å‹é…ç½®
    å°† qwen3-embedding-4b æ›¿æ¢ä¸º openai/qwen3-embedding-0.6b
    """
    print("=== è®¾ç½® Qwen Embedding æ¨¡å‹ ===")
    
    manager = EmbeddingProviderManager()
    
    try:
        # 1. æ£€æŸ¥å½“å‰æ´»è·ƒæ¨¡å‹
        print("1. æ£€æŸ¥å½“å‰æ´»è·ƒçš„ embedding æ¨¡å‹...")
        active_model = manager.get_current_active_embedding_model()
        if active_model:
            print(f"å½“å‰æ´»è·ƒæ¨¡å‹: {active_model.get('model_name')} (ID: {active_model.get('id')})")
        
        # 2. åˆ›å»ºæ–°çš„ LiteLLM Provider é…ç½®
        print("2. åˆ›å»ºæ–°çš„ LiteLLM Embedding Provider é…ç½®...")
        config = EmbeddingProviderConfig(
            provider_type="litellm",
            api_key="sk-Zd7gzQGylVwOyUUMvOBhow",
            api_url="http://172.16.0.120:4000/v1/embeddings"  # ä½¿ç”¨å®Œæ•´çš„åµŒå…¥ç«¯ç‚¹
        )
        
        result = manager.create_or_update_embedding_provider(config)
        print("âœ“ LiteLLM Embedding Provider é…ç½®æˆåŠŸ")
        
        # 3. æµ‹è¯•æ–°æ¨¡å‹
        print("3. æµ‹è¯• qwen3-embedding-0.6b æ¨¡å‹...")
        test_config = EmbeddingProviderTemplates.create_test_config(
            provider_type="litellm",
            model_name="openai/qwen3-embedding-0.6b",
            api_key="sk-Zd7gzQGylVwOyUUMvOBhow",
            api_url="http://172.16.0.120:4000/v1/embeddings"
        )
        
        if not manager.test_embedding_provider(test_config):
            print("âœ— æ–°çš„ embedding æ¨¡å‹æµ‹è¯•å¤±è´¥")
            return False
        
        print("âœ“ æ–°çš„ embedding æ¨¡å‹æµ‹è¯•æˆåŠŸ")
        
        # 4. åˆ›å»ºæ–°çš„é»˜è®¤ embedding æ¨¡å‹
        print("4. åˆ›å»ºæ–°çš„é»˜è®¤ embedding æ¨¡å‹...")
        if manager.create_new_embedding_model("openai/qwen3-embedding-0.6b", "litellm"):
            print("âœ“ æ–°çš„é»˜è®¤ embedding æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        else:
            print("âœ— æ–°çš„é»˜è®¤ embedding æ¨¡å‹åˆ›å»ºå¤±è´¥")
            return False
        
        # 5. æ¿€æ´»æ–°çš„ embedding æ¨¡å‹
        print("5. æ¿€æ´»æ–°çš„ qwen3-embedding-0.6b æ¨¡å‹...")
        if manager.set_active_embedding_model("openai/qwen3-embedding-0.6b"):
            print("âœ“ æ–°æ¨¡å‹æ¿€æ´»æˆåŠŸ")
        else:
            print("âœ— æ–°æ¨¡å‹æ¿€æ´»å¤±è´¥")
            return False
        
        # 6. ç­‰å¾…æ–°æ¨¡å‹æˆä¸ºæ´»è·ƒçŠ¶æ€ï¼Œç„¶åæ¸…ç†æ—§æ¨¡å‹
        print("6. æ¸…ç†æ—§çš„ qwen3-embedding-4b æ¨¡å‹...")
        cleanup_success = manager.cleanup_old_qwen_models(skip_active=False)
        
        if cleanup_success:
            print("âœ“ æ—§æ¨¡å‹æ¸…ç†æˆåŠŸ")
        else:
            print("âš ï¸ éƒ¨åˆ†æ—§æ¨¡å‹æ¸…ç†å¤±è´¥ï¼Œä½†ä¸å½±å“æ–°æ¨¡å‹ä½¿ç”¨")
        
        print("ğŸ‰ Qwen Embedding æ¨¡å‹é…ç½®å®Œæˆï¼")
        return True
            
    except Exception as e:
        print(f"âœ— é…ç½®å¤±è´¥: {e}")
        return False


# å¦‚æœåªæƒ³è®¾ç½® qwen embeddingï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š
if __name__ == "__main__":
    # é‡æ–°è®¾ç½® qwen embedding æ¨¡å‹
    setup_qwen_embedding()
    
    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print("\n" + "="*50)

    print("æœ€ç»ˆçš„æ¨¡å‹åˆ—è¡¨:")
    list_all_embedding_models()