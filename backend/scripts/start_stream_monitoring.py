#!/usr/bin/env python3
"""
å¯åŠ¨æµå¼ç›‘æŽ§
è‡ªåŠ¨ç›‘æŽ§å’Œåˆ†æžæ–°çš„æµå¼æ—¥å¿—
"""
import os
import time
import json
from datetime import datetime
from pathlib import Path


def monitor_stream_logs(log_dir="/tmp/onyx_stream_logs", watch_interval=2):
    """ç›‘æŽ§æµå¼æ—¥å¿—ç›®å½•ï¼Œè‡ªåŠ¨åˆ†æžæ–°æ–‡ä»¶"""
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    Path(log_dir).mkdir(exist_ok=True)
    
    print(f"ðŸ” å¼€å§‹ç›‘æŽ§æµå¼æ—¥å¿—ç›®å½•: {log_dir}")
    print(f"â±ï¸  æ£€æŸ¥é—´éš”: {watch_interval} ç§’")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æŽ§\n")
    
    processed_files = set()
    
    try:
        while True:
            # æ‰«ææ—¥å¿—æ–‡ä»¶
            current_files = set()
            if os.path.exists(log_dir):
                current_files = {
                    os.path.join(log_dir, f) 
                    for f in os.listdir(log_dir) 
                    if f.startswith("stream_") and f.endswith(".json")
                }
            
            # æ£€æŸ¥æ–°æ–‡ä»¶
            new_files = current_files - processed_files
            for file_path in new_files:
                try:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆåŒ…å« "complete": trueï¼‰
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    if data.get('complete'):
                        print(f"ðŸ“ å‘çŽ°æ–°çš„å®Œæ•´æ—¥å¿—: {os.path.basename(file_path)}")
                        analyze_log_file_quickly(file_path, data)
                        processed_files.add(file_path)
                        print("-" * 60)
                    
                except Exception as e:
                    # æ–‡ä»¶å¯èƒ½è¿˜åœ¨å†™å…¥ä¸­
                    pass
            
            time.sleep(watch_interval)
            
    except KeyboardInterrupt:
        print("\nðŸ›‘ ç›‘æŽ§å·²åœæ­¢")


def analyze_log_file_quickly(file_path: str, log_data: dict):
    """å¿«é€Ÿåˆ†æžæ—¥å¿—æ–‡ä»¶"""
    print(f"ðŸ• æ—¶é—´: {log_data.get('start_time', 'N/A')}")
    print(f"ðŸ‘¤ ç”¨æˆ·: {log_data.get('request_info', {}).get('user_email', 'N/A')}")
    print(f"ðŸ’¬ æ¶ˆæ¯: {log_data.get('request_info', {}).get('message', 'N/A')[:50]}...")
    print(f"ðŸ“¦ æ€»åŒ…æ•°: {log_data.get('total_packets', 0)}")
    
    # ç»Ÿè®¡å…³é”®æ•°æ®åŒ…
    packets = log_data.get('packets', [])
    sub_questions = []
    documents_count = 0
    answer_length = 0
    
    for packet in packets:
        parsed = packet.get('parsed_data', {})
        if 'sub_question' in parsed:
            sub_questions.append(f"[{parsed.get('level', '?')}.{parsed.get('level_question_num', '?')}] {parsed['sub_question']}")
        elif 'top_documents' in parsed:
            documents_count += len(parsed['top_documents'])
        elif 'answer_piece' in parsed and parsed.get('answer_type') != 'agent_sub_answer':
            answer_length += len(parsed.get('answer_piece', ''))
    
    if sub_questions:
        print(f"â“ å­é—®é¢˜ ({len(sub_questions)} ä¸ª):")
        for sq in sub_questions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"   {sq}")
        if len(sub_questions) > 3:
            print(f"   ... è¿˜æœ‰ {len(sub_questions) - 3} ä¸ª")
    
    print(f"ðŸ“„ æ–‡æ¡£æ•°: {documents_count}")
    print(f"ðŸ“ ç­”æ¡ˆé•¿åº¦: {answer_length} å­—ç¬¦")


def print_usage():
    """æ‰“å°ä½¿ç”¨è¯´æ˜Ž"""
    print("ðŸ”§ Onyx æµå¼ç›‘æŽ§å·¥å…·")
    print("=" * 50)
    print("åŠŸèƒ½:")
    print("  1. è‡ªåŠ¨ç›‘æŽ§æ–°çš„æµå¼æ—¥å¿—æ–‡ä»¶")
    print("  2. å®žæ—¶åˆ†æžå’Œå±•ç¤ºå…³é”®ä¿¡æ¯")
    print("  3. ç»Ÿè®¡å­é—®é¢˜ã€æ–‡æ¡£ã€ç­”æ¡ˆç­‰æ•°æ®")
    print()
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  python start_stream_monitoring.py      # å¼€å§‹ç›‘æŽ§")
    print("  python view_stream_logs.py --latest    # æŸ¥çœ‹æœ€æ–°æ—¥å¿—è¯¦æƒ…")
    print("  python view_stream_logs.py --help      # æŸ¥çœ‹è¯¦ç»†å¸®åŠ©")
    print()
    print("æ—¥å¿—ä½ç½®: /tmp/onyx_stream_logs/")
    print()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] in ["--help", "-h"]:
        print_usage()
    else:
        monitor_stream_logs()